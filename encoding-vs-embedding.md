# ğŸŸ¢ Encoding vs Embedding



| Feature                  | **Encoding**                                                                                                 | **Embedding**                                                                                             |
| ------------------------ | ------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------- |
| ğŸ”¤ **Definition**        | <mark style="color:purple;background-color:purple;">**Rule-based representation of words as numbers**</mark> | <mark style="color:purple;background-color:purple;">**Learned representation of words as vectors**</mark> |
| ğŸ”¢ **Vector Type**       | <mark style="color:purple;background-color:purple;">**Sparse (mostly 0s)**</mark>                            | <mark style="color:purple;background-color:purple;">**Dense (real numbers)**</mark>                       |
| ğŸ§  **Captures Meaning?** | <mark style="color:purple;background-color:purple;">**âŒ No**</mark>                                          | <mark style="color:purple;background-color:purple;">**âœ… Yes (semantic similarity)**</mark>                |
| ğŸ§® **Dimensionality**    | High (equal to vocabulary size)                                                                              | Low (e.g., 100â€“768 dimensions)                                                                            |
| ğŸ§¾ **Representation**    | <mark style="color:purple;background-color:purple;">**Fixed and manual**</mark>                              | <mark style="color:purple;background-color:purple;">**Learned from data**</mark>                          |
| ğŸ” **Context Aware?**    | <mark style="color:purple;background-color:purple;">**âŒ No (same vector always)**</mark>                     | <mark style="color:blue;background-color:purple;">**âœ… (contextual if using models like BERT)**</mark>     |
| ğŸ“š **Examples**          | One-Hot, Bag of Words, TF-IDF                                                                                | Word2Vec, GloVe, FastText, BERT                                                                           |
| ğŸ” **Similarity Info**   | Not captured                                                                                                 | Captured (similar words are close)                                                                        |
| âš™ï¸ **Use Case**          | Simple ML models                                                                                             | NLP models, deep learning, semantic tasks                                                                 |
