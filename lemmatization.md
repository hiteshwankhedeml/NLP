# Lemmatization

* Reduces a word to its base form while considering the context and the words grammatical meaning
* More sophisticated and linguistic informed
* The output is always a valid word
* running ⇒ run
* better ⇒ good
* WordNet Lemmatizer in nltk
* spacy&#x20;
* Useful in tasks like machine learning
* Slower



* In classical NLP models like RNN, LSTM, GRU etc pre processing techniques like stemming, lemmatization was required so that models understand the data
* LLMs are already trained on huge data
* Even if data is having lot of error, ambuiguity still LLM can handle it, as it was trained on huge amount of data
* So text preprocessing is not always needed for LLM
* But if data having lots of error then in that case, preprocessing is required

